# Regresyon ve Ä°zdÃ¼ÅŸÃ¼m ile Tahmin Projesi

## ğŸ“š Proje AmacÄ±

Bu proje, **doÄŸrusal regresyon** kullanarak baÄŸÄ±msÄ±z deÄŸiÅŸkenlerin baÄŸÄ±mlÄ± deÄŸiÅŸkene nasÄ±l izdÃ¼ÅŸÃ¼m yaptÄ±ÄŸÄ±nÄ± gÃ¶rsel ve pratik olarak anlamayÄ± hedefler. Makine Ã¶ÄŸrenmesinin temel konularÄ±ndan biri olan regresyon analizi, veri setini eÄŸitim ve test setlerine ayÄ±rma, model eÄŸitimi ve tahmin yapma sÃ¼reÃ§lerini kapsar.

---

## ğŸ¯ Regresyon Nedir?

**Regresyon**, baÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) ile baÄŸÄ±mlÄ± deÄŸiÅŸken (y) arasÄ±ndaki matematiksel iliÅŸkiyi modelleme yÃ¶ntemidir.

### Matematiksel GÃ¶sterim:
```
y = wâ‚Â·xâ‚ + wâ‚‚Â·xâ‚‚ + ... + wâ‚™Â·xâ‚™ + b
```

- **y**: Tahmin edilecek deÄŸer (baÄŸÄ±mlÄ± deÄŸiÅŸken)
- **xâ‚, xâ‚‚, ..., xâ‚™**: Girdiler (baÄŸÄ±msÄ±z deÄŸiÅŸkenler)
- **wâ‚, wâ‚‚, ..., wâ‚™**: AÄŸÄ±rlÄ±klar (katsayÄ±lar) - her Ã¶zelliÄŸin Ã¶nemi
- **b**: Bias (kesim noktasÄ±)

---

## ğŸ” Ä°zdÃ¼ÅŸÃ¼m (Projection) KavramÄ±

Regresyonda **izdÃ¼ÅŸÃ¼m**, Ã§ok boyutlu uzaydaki veri noktalarÄ±nÄ±n bir doÄŸru veya dÃ¼zlem Ã¼zerine projeksiyon edilmesi anlamÄ±na gelir.

### Geometrik AÃ§Ä±klama:
1. **BaÄŸÄ±msÄ±z deÄŸiÅŸkenler** (X): Ã‡ok boyutlu bir uzayda noktalar oluÅŸturur
2. **Regresyon doÄŸrusu/dÃ¼zlemi**: Bu noktalarÄ± en iyi temsil eden Ã§izgi
3. **Ä°zdÃ¼ÅŸÃ¼m**: Her veri noktasÄ±nÄ±n regresyon doÄŸrusuna dik uzaklÄ±ÄŸÄ± minimize edilir

Bu iÅŸlem, **En KÃ¼Ã§Ã¼k Kareler YÃ¶ntemi (Least Squares)** ile gerÃ§ekleÅŸtirilir:
```
Minimize: Î£(y_gerÃ§ek - y_tahmin)Â²
```

---

## ğŸ“‚ Proje YapÄ±sÄ±

```
regresyon_izdusumu_projesi/
â”‚
â”œâ”€â”€ README.md                    # Bu dosya - proje aÃ§Ä±klamasÄ±
â”œâ”€â”€ requirements.txt             # Gerekli Python kÃ¼tÃ¼phaneleri
â”‚
â”œâ”€â”€ 1_basit_regresyon.py        # Tek deÄŸiÅŸkenli basit regresyon
â”œâ”€â”€ 2_coklu_regresyon.py        # Ã‡ok deÄŸiÅŸkenli regresyon
â”œâ”€â”€ 3_izdusumu_gorsellestirme.py # Ä°zdÃ¼ÅŸÃ¼m gÃ¶rselleÅŸtirmesi (3D)
â”‚
â””â”€â”€ data/                        # Veri setleri (isteÄŸe baÄŸlÄ±)
```

---

## ğŸš€ Kurulum

### Gerekli KÃ¼tÃ¼phaneler:
```bash
pip install -r requirements.txt
```

**requirements.txt iÃ§eriÄŸi:**
```
numpy
pandas
scikit-learn
matplotlib
seaborn
```

---

## ğŸ“ Kod Ana HatlarÄ±

### 1ï¸âƒ£ VERÄ° HAZIRLAMA
```python
# Veri setini yÃ¼kle veya oluÅŸtur
import pandas as pd
from sklearn.datasets import load_boston

data = load_boston()
X = data.data  # BaÄŸÄ±msÄ±z deÄŸiÅŸkenler
y = data.target  # BaÄŸÄ±mlÄ± deÄŸiÅŸken
```

**AmaÃ§:** Ham veriyi modele uygun formata getirmek.

---

### 2ï¸âƒ£ VERÄ°YÄ° BÃ–LME (Train-Test Split)
```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,    # %20 test, %80 eÄŸitim
    random_state=42   # Tekrarlanabilirlik iÃ§in
)
```

**Neden bÃ¶lÃ¼yoruz?**
- **EÄŸitim seti**: Modelin Ã¶ÄŸrenmesi iÃ§in
- **Test seti**: Modelin gerÃ§ek performansÄ±nÄ± Ã¶lÃ§mek iÃ§in (gÃ¶rmediÄŸi veriler)

---

### 3ï¸âƒ£ MODEL OLUÅTURMA
```python
from sklearn.linear_model import LinearRegression

model = LinearRegression()
```

**Model parametreleri:**
- `fit_intercept=True`: Bias terimini (b) otomatik hesapla
- `normalize=False`: Veri normalizasyonu (isteÄŸe baÄŸlÄ±)

---

### 4ï¸âƒ£ MODEL EÄÄ°TÄ°MÄ°
```python
model.fit(X_train, y_train)
```

**Arka planda olan:**
1. Model, w (aÄŸÄ±rlÄ±klar) ve b (bias) deÄŸerlerini hesaplar
2. En kÃ¼Ã§Ã¼k kareler yÃ¶ntemiyle hata minimize edilir
3. **Ä°zdÃ¼ÅŸÃ¼m** burada gerÃ§ekleÅŸir: Veri noktalarÄ± regresyon dÃ¼zlemine projeksiyon edilir

---

### 5ï¸âƒ£ TAHMÄ°N YAPMA
```python
y_pred = model.predict(X_test)
```

**Tahmin denklemi:**
```
y_pred = wâ‚Â·xâ‚ + wâ‚‚Â·xâ‚‚ + ... + wâ‚™Â·xâ‚™ + b
```

---

### 6ï¸âƒ£ MODEL DEÄERLENDÄ°RME
```python
from sklearn.metrics import mean_squared_error, r2_score

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"MSE: {mse:.2f}")
print(f"RÂ² Skoru: {r2:.2f}")
```

**Metrikler:**
- **MSE (Mean Squared Error)**: Ortalama kare hata (dÃ¼ÅŸÃ¼k iyi)
- **RÂ² Skoru**: Modelin aÃ§Ä±klama gÃ¼cÃ¼ (0-1 arasÄ±, 1'e yakÄ±n iyi)

---

### 7ï¸âƒ£ MODEL KATSAYILARÄ°
```python
print("AÄŸÄ±rlÄ±klar (w):", model.coef_)
print("Bias (b):", model.intercept_)
```

**Yorumlama:**
- Pozitif katsayÄ±: X arttÄ±kÃ§a y artar
- Negatif katsayÄ±: X arttÄ±kÃ§a y azalÄ±r
- BÃ¼yÃ¼k katsayÄ±: O Ã¶zellik daha Ã¶nemli

---

### 8ï¸âƒ£ GÃ–RSELLEÅTÄ°RME (Ä°zdÃ¼ÅŸÃ¼m)
```python
import matplotlib.pyplot as plt

# 2D Ä°zdÃ¼ÅŸÃ¼m GÃ¶rselleÅŸtirmesi
plt.scatter(X_test, y_test, label='GerÃ§ek DeÄŸerler')
plt.plot(X_test, y_pred, color='red', label='Regresyon DoÄŸrusu')
plt.xlabel('BaÄŸÄ±msÄ±z DeÄŸiÅŸken')
plt.ylabel('BaÄŸÄ±mlÄ± DeÄŸiÅŸken')
plt.legend()
plt.show()
```

**3D Ä°zdÃ¼ÅŸÃ¼m:**
Ä°ki baÄŸÄ±msÄ±z deÄŸiÅŸken kullanarak 3 boyutlu uzayda regresyon dÃ¼zlemini gÃ¶rselleÅŸtirebiliriz.

---

## ğŸ§® Ä°zdÃ¼ÅŸÃ¼m MatematiÄŸi

### Normal Denklemler (Closed-Form Solution):
```
w = (Xáµ€X)â»Â¹Xáµ€y
```

Bu formÃ¼l, **projeksiyon matris teorisi** kullanarak optimal aÄŸÄ±rlÄ±klarÄ± hesaplar.

### Geometrik Anlam:
- Hata vektÃ¶rÃ¼ (e = y - Xw) regresyon dÃ¼zlemine **dik**tir
- Bu, veri noktalarÄ±nÄ±n dÃ¼zleme en kÄ±sa mesafede izdÃ¼ÅŸÃ¼m yapmasÄ±nÄ± saÄŸlar

---

## ğŸ“Š Ã–rnek KullanÄ±m

### Basit Regresyon:
```bash
python 1_basit_regresyon.py
```

### Ã‡oklu Regresyon:
```bash
python 2_coklu_regresyon.py
```

### 3D Ä°zdÃ¼ÅŸÃ¼m GÃ¶rselleÅŸtirmesi:
```bash
python 3_izdusumu_gorsellestirme.py
```

---

## ğŸ“ Ã–ÄŸrenme Hedefleri

Bu projeyi tamamladÄ±ktan sonra:
- âœ… Regresyonun matematiksel temellerini anlarsÄ±nÄ±z
- âœ… Ä°zdÃ¼ÅŸÃ¼m kavramÄ±nÄ± geometrik olarak kavrayacaksÄ±nÄ±z
- âœ… Veri setini eÄŸitim/test olarak ayÄ±rmayÄ± Ã¶ÄŸrenirsiniz
- âœ… Model performansÄ±nÄ± deÄŸerlendirme metriklerini kullanÄ±rsÄ±nÄ±z
- âœ… KatsayÄ±larÄ± yorumlayarak Ã¶zellik Ã¶nemini anlarsÄ±nÄ±z

---

## ğŸ“– Ek Kaynaklar

- [Scikit-Learn Documentation](https://scikit-learn.org/stable/modules/linear_model.html)
- [Linear Regression Mathematics](https://en.wikipedia.org/wiki/Linear_regression)
- [Least Squares Projection](https://en.wikipedia.org/wiki/Projection_(linear_algebra))

---

## ğŸ† Ä°leri Seviye Konular

- **Ridge Regression**: L2 regularizasyon ile overfitting Ã¶nleme
- **Lasso Regression**: L1 regularizasyon ile Ã¶zellik seÃ§imi
- **Polynomial Regression**: DoÄŸrusal olmayan iliÅŸkileri modelleme
- **Multiple Linear Regression**: Ã‡ok deÄŸiÅŸkenli izdÃ¼ÅŸÃ¼m

---

**HazÄ±rlayan:** BTK AtÃ¶lye - Multimedya GÃ¼venliÄŸi
**Tarih:** 2025
