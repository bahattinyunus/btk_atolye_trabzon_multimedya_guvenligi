# ğŸŒº K-Means ile Iris Ã‡iÃ§ek KÃ¼meleme Projesi

Bu proje, **K-Means KÃ¼meleme AlgoritmasÄ±**'nÄ± kullanarak Iris Ã§iÃ§ek tÃ¼rlerini denetimsiz Ã¶ÄŸrenme yÃ¶ntemiyle gruplandÄ±ran kapsamlÄ± bir makine Ã¶ÄŸrenmesi uygulamasÄ±dÄ±r.

## ğŸ“‹ Ä°Ã§indekiler

- [Proje HakkÄ±nda](#proje-hakkÄ±nda)
- [Kurulum](#kurulum)
- [KullanÄ±m](#kullanÄ±m)
- [Algoritma DetaylarÄ±](#algoritma-detaylarÄ±)
- [Kod YapÄ±sÄ±](#kod-yapÄ±sÄ±)
- [SonuÃ§lar](#sonuÃ§lar)
- [Teknik Detaylar](#teknik-detaylar)
- [Ã–ÄŸrenme Ã‡Ä±ktÄ±larÄ±](#Ã¶ÄŸrenme-Ã§Ä±ktÄ±larÄ±)

## ğŸ¯ Proje HakkÄ±nda

### AmaÃ§
Bu proje, **K-Means KÃ¼meleme** algoritmasÄ±nÄ±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± Ã¶ÄŸretmek ve **denetimsiz Ã¶ÄŸrenme** konseptini Iris Ã§iÃ§ek veri seti Ã¼zerinde pratik olarak gÃ¶stermeyi amaÃ§lar.

### Veri Seti
- **Iris Ã‡iÃ§ek Veri Seti** (scikit-learn'den)
- **150 Ã§iÃ§ek Ã¶rneÄŸi**
- **4 Ã¶zellik**: Ã‡anak ve taÃ§ yaprak uzunluk/geniÅŸlik
- **3 doÄŸal grup**: Setosa, Versicolor, Virginica

### Temel Ã–zellikler
- âœ… Denetimsiz Ã¶ÄŸrenme yaklaÅŸÄ±mÄ±
- âœ… K-Means kÃ¼meleme implementasyonu
- âœ… Veri Ã¶n iÅŸleme ve standardizasyon
- âœ… KÃ¼me merkezi analizi
- âœ… GerÃ§ek etiketlerle karÅŸÄ±laÅŸtÄ±rma
- âœ… Yeni veri noktalari tahmini
- âœ… KÃ¼me kalite deÄŸerlendirmesi

## ğŸ”§ Kurulum

### Gerekli KÃ¼tÃ¼phaneler
```bash
pip install numpy pandas scikit-learn
```

### Dosya YapÄ±sÄ±
```
â”œâ”€â”€ 7_kMeans_iris.py              # Ana uygulama dosyasÄ±
â””â”€â”€ README_7_kMeans_iris.md       # Bu dÃ¶kÃ¼man
```

## ğŸš€ KullanÄ±m

### Basit Ã‡alÄ±ÅŸtÄ±rma
```bash
python 7_kMeans_iris.py
```

### Program AkÄ±ÅŸÄ±
Program ÅŸu aÅŸamalarÄ± takip eder:
1. **Veri setini yÃ¼kleme ve inceleme**
2. **Veri standardizasyonu**
3. **K-Means model kurulumu**
4. **Model eÄŸitimi (kÃ¼meleme)**
5. **KÃ¼meleme sonuÃ§larÄ± analizi**
6. **GerÃ§ek tÃ¼rlerle karÅŸÄ±laÅŸtÄ±rma**
7. **KÃ¼me merkezi inceleme**
8. **Yeni veri tahmini**
9. **Performans deÄŸerlendirmesi**
10. **DetaylÄ± sonuÃ§ raporu**

## ğŸ§  Algoritma DetaylarÄ±

### K-Means Nedir?

K-Means, **denetimsiz Ã¶ÄŸrenme** algoritmasÄ±dÄ±r ve ÅŸu prensiple Ã§alÄ±ÅŸÄ±r:
- Veriyi **K adet kÃ¼me**ye ayÄ±rÄ±r
- Her nokta en yakÄ±n **kÃ¼me merkezine** atanÄ±r
- KÃ¼me merkezleri **iteratif** olarak gÃ¼ncellenir
- **YakÄ±nsama** saÄŸlanana kadar devam eder

### Algoritma AdÄ±mlarÄ±

1. **BaÅŸlangÄ±Ã§**: K adet rastgele kÃ¼me merkezi seÃ§
2. **Atama**: Her veri noktasÄ±nÄ± en yakÄ±n merkeze ata
3. **GÃ¼ncelleme**: KÃ¼me merkezlerini yeniden hesapla
4. **YakÄ±nsama**: Merkezler deÄŸiÅŸmeyene kadar tekrar et

### Denetimsiz Ã–ÄŸrenme AvantajlarÄ±
- **Etiket gerekmez**: Ã–nceden sÄ±nÄ±f bilgisi olmadan Ã§alÄ±ÅŸÄ±r
- **KeÅŸfedici**: Veri setindeki doÄŸal gruplarÄ± bulur
- **HÄ±zlÄ±**: BÃ¼yÃ¼k veri setlerinde etkili
- **Basit**: AnlamasÄ± ve uygulamasÄ± kolay

## ğŸ“ Kod YapÄ±sÄ±

### 1. Veri YÃ¼kleme ve Ä°nceleme
```python
# Iris veri setini yÃ¼kle (etiketleri kullanmayÄ±z!)
iris = load_iris()
X = iris.data  # Sadece Ã¶zellikler
y = iris.target  # Sadece doÄŸruluk kontrolÃ¼ iÃ§in
```

### 2. Veri Standardizasyonu
```python
# K-Means Ã¶lÃ§ek hassasiyeti vardÄ±r
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

### 3. K-Means Modeli
```python
# K=3 (Ã§Ã¼nkÃ¼ 3 Ã§iÃ§ek tÃ¼rÃ¼ olduÄŸunu biliyoruz)
kmeans = KMeans(n_clusters=3, random_state=42)
kmeans.fit(X_scaled)
```

### 4. KÃ¼meleme SonuÃ§larÄ±
```python
# KÃ¼me etiketlerini al
cluster_labels = kmeans.labels_
# KÃ¼me merkezlerini al
cluster_centers = kmeans.cluster_centers_
```

## ğŸ“Š SonuÃ§lar

### Beklenen Performans

| Metrik | DeÄŸer |
|--------|--------|
| **Genel DoÄŸruluk** | ~80-90% |
| **KÃ¼me SayÄ±sÄ±** | 3 |
| **Ä°terasyon** | 3-6 |
| **YakÄ±nsama** | HÄ±zlÄ± |

### KÃ¼me BaÅŸarÄ± OranlarÄ±

| Ã‡iÃ§ek TÃ¼rÃ¼ | KÃ¼meleme BaÅŸarÄ±sÄ± |
|------------|-------------------|
| **Setosa** | ~100% (MÃ¼kemmel) |
| **Versicolor** | ~70-80% |
| **Virginica** | ~70-80% |

### KÃ¼me Merkezi Ã–zellikleri

| KÃ¼me | Ã‡anak Uzunluk | Ã‡anak GeniÅŸlik | TaÃ§ Uzunluk | TaÃ§ GeniÅŸlik |
|------|---------------|----------------|-------------|--------------|
| **0** | ~5.8 cm | ~2.7 cm | ~4.4 cm | ~1.4 cm |
| **1** | ~5.0 cm | ~3.4 cm | ~1.5 cm | ~0.2 cm |
| **2** | ~6.8 cm | ~3.1 cm | ~5.5 cm | ~2.0 cm |

## âš™ï¸ Teknik Detaylar

### K-Means Parametreleri

**n_clusters**: KÃ¼me sayÄ±sÄ±
- Bu projede **K=3** (3 Ã§iÃ§ek tÃ¼rÃ¼ iÃ§in)

**random_state**: Rastgelelik kontrolÃ¼
- **42** (tekrarlanabilir sonuÃ§lar iÃ§in)

**n_init**: FarklÄ± baÅŸlangÄ±Ã§ denemesi
- **10** (en iyi sonucu seÃ§mek iÃ§in)

**max_iter**: Maksimum iterasyon
- **300** (yakÄ±nsama iÃ§in yeterli)

### Mesafe Hesaplama
- **Ã–klid mesafesi** kullanÄ±lÄ±r
- **Standardizasyon** kritik Ã¶neme sahiptir
- **KÃ¼me merkezleri** sÃ¼rekli gÃ¼ncellenir

### DeÄŸerlendirme Metrikleri

**KÃ¼me Ä°Ã§ TutarlÄ±lÄ±k**:
- AynÄ± kÃ¼medeki noktalar benzer olmalÄ±

**KÃ¼me AyrÄ±mÄ±**:
- FarklÄ± kÃ¼meler birbirinden uzak olmalÄ±

**Silhouette Score**:
- KÃ¼me kalitesini Ã¶lÃ§er (-1 ile +1 arasÄ±)

## ğŸ“ Ã–ÄŸrenme Ã‡Ä±ktÄ±larÄ±

Bu projeyi tamamladÄ±ktan sonra Ã¶ÄŸrenecekleriniz:

### Teorik Bilgiler
- âœ… **Denetimsiz Ã¶ÄŸrenme** konsepti
- âœ… **K-Means algoritmasÄ±** Ã§alÄ±ÅŸma prensibi
- âœ… **KÃ¼me analizi** teknikleri
- âœ… **Mesafe metrikleri** kullanÄ±mÄ±
- âœ… **YakÄ±nsama** kriterleri
- âœ… **KÃ¼me sayÄ±sÄ±** seÃ§im stratejileri

### Pratik Beceriler
- âœ… **Scikit-learn** ile kÃ¼meleme
- âœ… **Veri Ã¶n iÅŸleme** teknikleri
- âœ… **KÃ¼me gÃ¶rselleÅŸtirmesi**
- âœ… **Model deÄŸerlendirmesi**
- âœ… **SonuÃ§ yorumlama**

## ğŸ” Program Ã‡Ä±ktÄ±sÄ± Analizi

### BaÅŸarÄ± DeÄŸerlendirmesi

**MÃ¼kemmel (>%85)**:
- Setosa tamamen ayrÄ±lÄ±r
- DiÄŸer tÃ¼rlerde minimal karÄ±ÅŸÄ±klÄ±k

**Ä°yi (%75-85)**:
- Ã‡oÄŸu Ã§iÃ§ek doÄŸru kÃ¼melenir
- BazÄ± sÄ±nÄ±r vakalarÄ± karÄ±ÅŸÄ±r

**Orta (%65-75)**:
- Genel grup yapÄ±sÄ± korunur
- Versicolor-Virginica karÄ±ÅŸÄ±klÄ±ÄŸÄ±

**ZayÄ±f (<%65)**:
- KÃ¼meleme rastgele gÃ¶rÃ¼nÃ¼r
- Algoritmik parametreler gÃ¶zden geÃ§irilmeli

### KÃ¼me Kalite Ä°ndikatÃ¶rleri

1. **Setosa Ä°zolasyonu**: En kolay ayrÄ±lan grup
2. **KÃ¼me Boyut Dengesi**: ~50'ÅŸer Ã§iÃ§ek ideal
3. **Merkez Stabilite**: Az iterasyonda yakÄ±nsama
4. **Ã–zellik AyrÄ±mÄ±**: TaÃ§ yaprak en belirleyici

## ğŸ› ï¸ Troubleshooting

### SÄ±k KarÅŸÄ±laÅŸÄ±lan Sorunlar

**Problem**: DÃ¼ÅŸÃ¼k kÃ¼meleme kalitesi
**Ã‡Ã¶zÃ¼mler**:
- Veri standardizasyonu uygulayÄ±n
- FarklÄ± K deÄŸerleri deneyin
- Random state deÄŸiÅŸtirin
- Daha fazla n_init kullanÄ±n

**Problem**: YavaÅŸ yakÄ±nsama
**Ã‡Ã¶zÃ¼mler**:
- max_iter artÄ±rÄ±n
- Daha iyi baÅŸlangÄ±Ã§ noktalarÄ± seÃ§in
- Veri Ã¶n iÅŸlemeyi kontrol edin

**Problem**: Ä°stikrarsÄ±z sonuÃ§lar
**Ã‡Ã¶zÃ¼mler**:
- random_state sabitleyip
- n_init deÄŸerini artÄ±rÄ±n
- Veri kalitesini kontrol edin

## ğŸ”¬ Denetimsiz vs Denetimli Ã–ÄŸrenme

### Bu Projede KarÅŸÄ±laÅŸtÄ±rma

| Ã–zellik | K-Means (Denetimsiz) | SVM (Denetimli) |
|---------|----------------------|-----------------|
| **Etiket Gereksinimi** | HayÄ±r | Evet |
| **DoÄŸruluk** | ~83% | ~97% |
| **KeÅŸif YeteneÄŸi** | YÃ¼ksek | DÃ¼ÅŸÃ¼k |
| **HÄ±z** | HÄ±zlÄ± | Orta |
| **Yorumlama** | Kolay | Orta |

### Ne Zaman Hangisini KullanmalÄ±?

**K-Means Tercih Edilir**:
- Etiket yoksa
- Veri keÅŸfi amaÃ§lÄ±ysa
- HÄ±zlÄ± sonuÃ§ gerekiyorsa
- Grup yapÄ±sÄ±nÄ± anlamak istiyorsak

**SVM Tercih Edilir**:
- Etiket mevcutsa
- YÃ¼ksek doÄŸruluk gerekiyorsa
- SÄ±nÄ±flandÄ±rma amaÃ§lÄ±ysa
- KarmaÅŸÄ±k karar sÄ±nÄ±rlarÄ± varsa

## ğŸ“ˆ GeliÅŸmiÅŸ Ã–zellikler

### Optimal K SeÃ§imi (Elbow Method)
```python
# FarklÄ± K deÄŸerleri iÃ§in WCSS hesapla
wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i)
    kmeans.fit(X_scaled)
    wcss.append(kmeans.inertia_)
```

### Silhouette Analizi
```python
from sklearn.metrics import silhouette_score
score = silhouette_score(X_scaled, cluster_labels)
```

### KÃ¼me GÃ¶rselleÅŸtirme
```python
import matplotlib.pyplot as plt
# PCA ile 2D'ye indirge ve gÃ¶rselleÅŸtir
```

## ğŸ“š Ek Kaynaklar

### Teorik Kaynaklar
- [K-Means Wikipedia](https://en.wikipedia.org/wiki/K-means_clustering)
- [Scikit-learn K-Means](https://scikit-learn.org/stable/modules/clustering.html#k-means)
- [Clustering Algorithms Comparison](https://scikit-learn.org/stable/modules/clustering.html)

### Pratik Kaynaklar
- [K-Means Tutorial](https://www.datacamp.com/tutorial/k-means-clustering-python)
- [Clustering Evaluation](https://scikit-learn.org/stable/modules/clustering.html#clustering-evaluation)

## ğŸ’¡ Ä°leri Seviye Konular

### K-Means VaryasyonlarÄ±
- **K-Means++**: Daha iyi baÅŸlangÄ±Ã§ seÃ§imi
- **Mini-batch K-Means**: BÃ¼yÃ¼k veriler iÃ§in
- **Fuzzy C-Means**: YumuÅŸak kÃ¼meleme

### Alternatif KÃ¼meleme AlgoritmalarÄ±
- **Hierarchical Clustering**: Dendogram ile
- **DBSCAN**: YoÄŸunluk tabanlÄ±
- **Gaussian Mixture Models**: OlasÄ±lÄ±ksal yaklaÅŸÄ±m

## ğŸ¯ Proje GeniÅŸletme Fikirleri

1. **GÃ¶rselleÅŸtirme**: KÃ¼meleri 2D/3D Ã§izim
2. **Optimizasyon**: Otomatik K seÃ§imi
3. **KarÅŸÄ±laÅŸtÄ±rma**: DiÄŸer algoritmalarla
4. **Interaktif**: Web arayÃ¼zÃ¼ ekleme
5. **GerÃ§ek Veri**: FarklÄ± veri setlerinde test

---

**ğŸ”— Ä°lgili Projeler**: 
- `6_destekvektor_iris.py` - SVM SÄ±nÄ±flandÄ±rma
- `anamoli_tespiti/` - Anomali Tespiti
- `kÃ¼meler/` - KÃ¼meleme Projeleri

**ğŸ“§ Ä°letiÅŸim**: BTK AtÃ¶lye Multimedya GÃ¼venliÄŸi Projesi kapsamÄ±nda hazÄ±rlanmÄ±ÅŸtÄ±r.

**ğŸ·ï¸ Etiketler**: #MachineLearning #Clustering #KMeans #UnsupervisedLearning #Iris #DataScience #Python