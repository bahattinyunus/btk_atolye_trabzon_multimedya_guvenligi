# ğŸ¯ K-Means K DeÄŸeri SeÃ§imi Projesi

Bu proje, **K-Means KÃ¼meleme AlgoritmasÄ±**'nda en kritik parametrelerden biri olan **K deÄŸerini (kÃ¼me sayÄ±sÄ±nÄ±)** seÃ§mek iÃ§in kullanÄ±lan Ã§eÅŸitli yÃ¶ntemleri kapsamlÄ± bir ÅŸekilde gÃ¶stermektedir.

## ğŸ“‹ Ä°Ã§indekiler

- [Proje HakkÄ±nda](#proje-hakkÄ±nda)
- [Kurulum](#kurulum)
- [KullanÄ±m](#kullanÄ±m)
- [K DeÄŸeri SeÃ§im YÃ¶ntemleri](#k-deÄŸeri-seÃ§im-yÃ¶ntemleri)
- [Kod YapÄ±sÄ±](#kod-yapÄ±sÄ±)
- [SonuÃ§lar](#sonuÃ§lar)
- [Teknik Detaylar](#teknik-detaylar)
- [Ã–ÄŸrenme Ã‡Ä±ktÄ±larÄ±](#Ã¶ÄŸrenme-Ã§Ä±ktÄ±larÄ±)

## ğŸ¯ Proje HakkÄ±nda

### AmaÃ§
Bu proje, K-Means kÃ¼meleme algoritmasÄ±nda **en uygun K deÄŸerini** seÃ§mek iÃ§in kullanÄ±lan farklÄ± yaklaÅŸÄ±mlarÄ± Ã¶ÄŸretmeyi ve pratik olarak uygulamayÄ± amaÃ§lar.

### Problem
K-Means algoritmasÄ±nda **K (kÃ¼me sayÄ±sÄ±)** parametresi Ã¶nceden belirlenmesi gereken kritik bir deÄŸerdir. YanlÄ±ÅŸ K seÃ§imi:
- **Underclustering** (az kÃ¼me): FarklÄ± gruplar aynÄ± kÃ¼mede
- **Overclustering** (Ã§ok kÃ¼me): AynÄ± grup farklÄ± kÃ¼melerde

### Ã‡Ã¶zÃ¼m YÃ¶ntemleri
Bu proje 3 farklÄ± yaklaÅŸÄ±m kullanÄ±r:
- ğŸ”§ **Elbow Method (Dirsek YÃ¶ntemi)**
- ğŸ“Š **Silhouette Analysis**
- ğŸ§  **Domain Knowledge (Alan Bilgisi)**

## ğŸ”§ Kurulum

### Gerekli KÃ¼tÃ¼phaneler
```bash
pip install numpy scikit-learn
```

### Dosya YapÄ±sÄ±
```
â”œâ”€â”€ 8_kMeans_kDegerSecimi.py          # Ana uygulama dosyasÄ±
â””â”€â”€ README_8_kMeans_kDegerSecimi.md   # Bu dÃ¶kÃ¼man
```

## ğŸš€ KullanÄ±m

### Basit Ã‡alÄ±ÅŸtÄ±rma
```bash
python 8_kMeans_kDegerSecimi.py
```

### Program AkÄ±ÅŸÄ±
1. **Veri hazÄ±rlama** ve standardizasyon
2. **Elbow Method** analizi (K=1-7)
3. **Silhouette Score** hesaplama (K=2-7)
4. **Domain Knowledge** deÄŸerlendirmesi
5. **Final K deÄŸeri** seÃ§imi
6. **SeÃ§ilen K ile model** oluÅŸturma

## ğŸ“Š K DeÄŸeri SeÃ§im YÃ¶ntemleri

### 1. ğŸ”§ Elbow Method (Dirsek YÃ¶ntemi)

**Prensip**: WCSS (Within-Cluster Sum of Squares) deÄŸiÅŸimini analiz eder

**NasÄ±l Ã‡alÄ±ÅŸÄ±r**:
- FarklÄ± K deÄŸerleri iÃ§in WCSS hesaplanÄ±r
- WCSS azalma oranÄ± incelenir
- En bÃ¼yÃ¼k azalma sonrasÄ± "dirsek noktasÄ±" bulunur

```python
# WCSS hesaplama
wcss_list = []
for k in range(1, 8):
    kmeans = KMeans(n_clusters=k)
    kmeans.fit(X_scaled)
    wcss_list.append(kmeans.inertia_)
```

**AvantajlarÄ±**:
- âœ… Basit ve anlaÅŸÄ±lÄ±r
- âœ… GÃ¶rsel olarak yorumlanabilir
- âœ… HÄ±zlÄ± hesaplama

**DezavantajlarÄ±**:
- âŒ Dirsek noktasÄ± belirsiz olabilir
- âŒ Subjektif yorum gerektirir

### 2. ğŸ“Š Silhouette Analysis

**Prensip**: Her veri noktasÄ±nÄ±n kendi kÃ¼mesine ne kadar uygun olduÄŸunu Ã¶lÃ§er

**Silhouette Score**:
- **+1**: MÃ¼kemmel kÃ¼meleme
- **0**: KÃ¼me sÄ±nÄ±rÄ±nda
- **-1**: YanlÄ±ÅŸ kÃ¼mede

```python
# Silhouette score hesaplama
for k in range(2, 8):
    kmeans = KMeans(n_clusters=k)
    kmeans.fit(X_scaled)
    score = silhouette_score(X_scaled, kmeans.labels_)
```

**AvantajlarÄ±**:
- âœ… Objektif metrik
- âœ… KÃ¼me kalitesini doÄŸrudan Ã¶lÃ§er
- âœ… -1 ile +1 arasÄ± normalize deÄŸer

**DezavantajlarÄ±**:
- âŒ Hesaplama maliyeti yÃ¼ksek
- âŒ BÃ¼yÃ¼k veriler iÃ§in yavaÅŸ

### 3. ğŸ§  Domain Knowledge (Alan Bilgisi)

**Prensip**: Veri setinin doÄŸal yapÄ±sÄ±nÄ± bilmek

**Iris Veri Seti Ä°Ã§in**:
- 3 Ã§iÃ§ek tÃ¼rÃ¼ â†’ K=3 mantÄ±klÄ±
- Biyolojik sÄ±nÄ±flandÄ±rma â†’ DoÄŸal gruplar

**AvantajlarÄ±**:
- âœ… GerÃ§ek dÃ¼nya uyumu
- âœ… Yorumlanabilir sonuÃ§lar
- âœ… Ä°ÅŸ gereksinimlerine uygun

**DezavantajlarÄ±**:
- âŒ Her zaman mevcut deÄŸil
- âŒ Ã–znel deÄŸerlendirme
- âŒ Verinin gizli yapÄ±larÄ± kaÃ§Ä±rÄ±labilir

## ğŸ“ Kod YapÄ±sÄ±

### 1. Veri HazÄ±rlama
```python
# Iris veri setini yÃ¼kle ve standardize et
iris = load_iris()
X = iris.data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

### 2. Elbow Method Implementasyonu
```python
# K deÄŸerleri iÃ§in WCSS hesapla
K_degerleri = range(1, 8)
wcss_list = []
for k in K_degerleri:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X_scaled)
    wcss_list.append(kmeans.inertia_)
```

### 3. Silhouette Analizi
```python
# En iyi silhouette skorunu bul
best_silhouette = 0
best_k = 2
for k in range(2, 8):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X_scaled)
    silhouette = silhouette_score(X_scaled, kmeans.labels_)
    if silhouette > best_silhouette:
        best_silhouette = silhouette
        best_k = k
```

### 4. Final Karar MekanizmasÄ±
```python
# TÃ¼m yÃ¶ntemlerin Ã¶nerilerini birleÅŸtir
oylar = [dirsek_k, best_k, 3]  # Dirsek, Silhouette, Domain
final_k = max(set(oylar), key=oylar.count)
```

## ğŸ“ˆ SonuÃ§lar

### Beklenen Program Ã‡Ä±ktÄ±sÄ±

| YÃ¶ntem | Ã–nerilen K | DeÄŸer/Skor |
|--------|------------|------------|
| **Elbow Method** | K = 2 | En bÃ¼yÃ¼k WCSS azalmasÄ± |
| **Silhouette** | K = 2 | ~0.58 skor |
| **Domain Knowledge** | K = 3 | 3 Ã§iÃ§ek tÃ¼rÃ¼ |

### Tipik SonuÃ§ Analizi
- **K=2**: Setosa vs (Versicolor+Virginica)
- **K=3**: Setosa vs Versicolor vs Virginica
- **Algoritmik tercih**: K=2 (daha iyi metrikler)
- **MantÄ±ksal tercih**: K=3 (doÄŸal gruplar)

### WCSS DeÄŸiÅŸim Tablosu
```
K |   WCSS   | DeÄŸiÅŸim
1 |   600.0  |    -
2 |   222.4  |  377.6  â† En bÃ¼yÃ¼k dÃ¼ÅŸÃ¼ÅŸ
3 |   139.8  |   82.5
4 |   114.1  |   25.7
5 |    90.9  |   23.2
```

## âš™ï¸ Teknik Detaylar

### WCSS (Within-Cluster Sum of Squares)
**FormÃ¼l**: Î£(veri noktasÄ± - kÃ¼me merkezi)Â²
- KÃ¼me iÃ§i homojenliÄŸi Ã¶lÃ§er
- DÃ¼ÅŸÃ¼k WCSS = Ä°yi kÃ¼meleme
- K arttÄ±kÃ§a her zaman azalÄ±r

### Silhouette Score Hesaplama
**FormÃ¼l**: (b - a) / max(a, b)
- **a**: Kendi kÃ¼mesindeki ortalama mesafe
- **b**: En yakÄ±n diÄŸer kÃ¼medeki ortalama mesafe

### Model Parametreleri
```python
KMeans(
    n_clusters=k,      # KÃ¼me sayÄ±sÄ±
    random_state=42,   # Tekrarlanabilirlik
    n_init=10,         # 10 farklÄ± baÅŸlangÄ±Ã§
    max_iter=300       # Maksimum iterasyon
)
```

## ğŸ“ Ã–ÄŸrenme Ã‡Ä±ktÄ±larÄ±

### Teorik Bilgiler
- âœ… **Elbow Method** prensipleri
- âœ… **Silhouette Analysis** hesaplamasÄ±
- âœ… **WCSS** kavramÄ± ve Ã¶nemi
- âœ… **Optimal K seÃ§imi** stratejileri
- âœ… **Domain Knowledge** kullanÄ±mÄ±
- âœ… **Bias-Variance tradeoff** kÃ¼melemede

### Pratik Beceriler
- âœ… **K deÄŸeri optimizasyonu**
- âœ… **Ã‡oklu metrik deÄŸerlendirmesi**
- âœ… **SonuÃ§ yorumlama** teknikleri
- âœ… **Karar verme** sÃ¼reci
- âœ… **Model validasyonu**

## ğŸ” Program Ã‡Ä±ktÄ±sÄ± Yorumlama

### Elbow Method SonuÃ§larÄ±
**K=1 â†’ K=2**: BÃ¼yÃ¼k WCSS azalmasÄ± (377.6)
- Bu en Ã¶nemli iyileÅŸtirme
- Veriyi 2 ana gruba ayÄ±rmanÄ±n faydalÄ± olduÄŸunu gÃ¶sterir

**K=2 â†’ K=3**: Orta seviye azalma (82.5)
- Hala anlamlÄ± bir iyileÅŸtirme
- 3. kÃ¼menin eklenmesinin deÄŸerli olabileceÄŸini gÃ¶sterir

**K=3+**: KÃ¼Ã§Ã¼k azalmalar
- Diminishing returns (azalan verim)
- Fazla kÃ¼meleme riski

### Silhouette SonuÃ§larÄ±
**K=2**: En yÃ¼ksek skor (0.582)
- Veri setini 2 gruba ayÄ±rmanÄ±n en uygun olduÄŸunu gÃ¶sterir
- Setosa'nÄ±n diÄŸerlerinden net ayrÄ±mÄ±nÄ± yansÄ±tÄ±r

**K=3**: Azalan skor (0.460)
- Versicolor-Virginica arasÄ± benzerlik nedeniyle dÃ¼ÅŸÃ¼ÅŸ
- Yine de kabul edilebilir seviyede

### Domain Knowledge DeÄŸerlendirmesi
**Biyolojik GerÃ§ek**: 3 farklÄ± Ã§iÃ§ek tÃ¼rÃ¼
- Ä°ris Setosa: DiÄŸerlerinden Ã§ok farklÄ±
- Iris Versicolor: Orta Ã¶zellikler
- Iris Virginica: Versicolor'a benzer

## ğŸ¤” Hangi K'yÄ± SeÃ§meli?

### Senaryo Analizi

**K=2 SeÃ§ilirse**:
- âœ… En iyi algoritmik metrikler
- âœ… Net kÃ¼me ayrÄ±mÄ±
- âŒ Biyolojik gerÃ§ekliÄŸi kaÃ§Ä±rÄ±r
- **KullanÄ±m**: Basit sÄ±nÄ±flandÄ±rma gerekiyorsa

**K=3 SeÃ§ilirse**:
- âœ… Biyolojik gerÃ§eklik
- âœ… Yorumlanabilir sonuÃ§lar
- âŒ DÃ¼ÅŸÃ¼k silhouette skor
- **KullanÄ±m**: DetaylÄ± analiz gerekiyorsa

### Karar Rehberi
1. **Ä°ÅŸ gereksinimini** belirle
2. **Veri yapÄ±sÄ±nÄ±** anla
3. **Metrikleri** karÅŸÄ±laÅŸtÄ±r
4. **Pratik kullanÄ±mÄ±** dÃ¼ÅŸÃ¼n
5. **Final kararÄ±** ver

## ğŸ› ï¸ Troubleshooting

### SÄ±k KarÅŸÄ±laÅŸÄ±lan Durumlar

**Belirsiz Elbow NoktasÄ±**:
- Daha fazla K deÄŸeri dene
- GÃ¶rselleÅŸtirme ekle
- Ä°kinci tÃ¼rev hesapla

**DÃ¼ÅŸÃ¼k Silhouette SkorlarÄ±**:
- Veri Ã¶n iÅŸlemeyi kontrol et
- PCA boyut azaltma uygula
- FarklÄ± kÃ¼meleme algoritmasÄ± dene

**Ã‡eliÅŸkili SonuÃ§lar**:
- Domain knowledge'Ä± Ã¶n planda tut
- Hibrit yaklaÅŸÄ±m kullan
- A/B testing yap

## ğŸ¯ Ä°leri Seviye Teknikler

### Gap Statistic
```python
# Rastgele veri ile karÅŸÄ±laÅŸtÄ±rma
gap_stats = []
for k in range(1, 8):
    # GerÃ§ek veri WCSS'si
    real_wcss = calculate_wcss(X, k)
    # Rastgele veri WCSS'si
    random_wcss = calculate_random_wcss(X.shape, k)
    gap = np.log(random_wcss) - np.log(real_wcss)
    gap_stats.append(gap)
```

### X-Means AlgoritmasÄ±
- Otomatik K seÃ§imi
- BIC (Bayesian Information Criterion) kullanÄ±r
- K alt ve Ã¼st sÄ±nÄ±rlarÄ± belirlenir

### GÃ¶rselleÅŸtirme Ä°yileÅŸtirmeleri
```python
import matplotlib.pyplot as plt
# WCSS eÄŸrisi
plt.plot(K_degerleri, wcss_list, 'bo-')
plt.xlabel('K deÄŸeri')
plt.ylabel('WCSS')
plt.title('Elbow Method')
```

## ğŸ“š Ek Kaynaklar

### Akademik Makaleler
- [Determining the number of clusters](https://web.stanford.edu/~hastie/Papers/gap.pdf)
- [Silhouette Analysis](https://www.sciencedirect.com/science/article/pii/0377042787901257)

### Praktik Kaynaklar
- [K-Means Clustering in Python](https://realpython.com/k-means-clustering-python/)
- [Choosing the number of clusters](https://towardsdatascience.com/clustering-metrics-better-than-the-elbow-method-6926e1f723a6)

### AraÃ§lar ve KÃ¼tÃ¼phaneler
- **Scikit-learn**: Temel implementasyon
- **Yellowbrick**: GÃ¶rselleÅŸtirme araÃ§larÄ±
- **Kneed**: Otomatik elbow detection

## ğŸ”¬ Deneysel GeniÅŸletmeler

### FarklÄ± Veri Setleri
- **Make_blobs**: Sentetik kÃ¼me verileri
- **Wholesale customers**: GerÃ§ek iÅŸ verisi
- **Image segmentation**: GÃ¶rÃ¼ntÃ¼ kÃ¼meleme

### Alternatif Metrikler
- **Calinski-Harabasz Index**
- **Davies-Bouldin Index**
- **Adjusted Rand Index**

### Hibrit YaklaÅŸÄ±mlar
```python
# AÄŸÄ±rlÄ±klÄ± karar verme
weights = {'elbow': 0.3, 'silhouette': 0.4, 'domain': 0.3}
final_score = sum(weights[method] * scores[method] for method in weights)
```

## ğŸ’¡ Best Practices

### Genel Ã–neriler
1. **HiÃ§ bir metrik tek baÅŸÄ±na yeterli deÄŸildir**
2. **Domain knowledge'Ä± gÃ¶z ardÄ± etmeyin**
3. **GÃ¶rselleÅŸtirme her zaman yardÄ±mcÄ±dÄ±r**
4. **Ã‡oklu metrik kullanÄ±n**
5. **Business impact'i unutmayÄ±n**

### Kod Kalitesi
- Reproducible results iÃ§in `random_state` kullanÄ±n
- Veriyi mutlaka standardize edin
- Exception handling ekleyin
- Logging implementasyonu yapÄ±n

## ğŸ¨ GÃ¶rselleÅŸtirme Fikirleri

### Temel Grafikler
```python
# Elbow curve
plt.plot(K_values, wcss_values)
# Silhouette scores
plt.bar(K_values, silhouette_scores)
# KÃ¼me daÄŸÄ±lÄ±mlarÄ±
plt.scatter(X[:, 0], X[:, 1], c=labels)
```

### Ä°leri Seviye
- **3D scatter plots**: Ã‡ok boyutlu veri
- **Heatmaps**: Mesafe matrisleri
- **Interactive plots**: Plotly ile
- **Animation**: KÃ¼me evrim sÃ¼reci

---

**ğŸ”— Ä°lgili Projeler**: 
- `7_kMeans_iris.py` - Temel K-Means Implementasyonu
- `6_destekvektor_iris.py` - SVM KarÅŸÄ±laÅŸtÄ±rmasÄ±
- `kÃ¼meler/` - DiÄŸer KÃ¼meleme Projeleri

**ğŸ“§ Ä°letiÅŸim**: BTK AtÃ¶lye Multimedya GÃ¼venliÄŸi Projesi kapsamÄ±nda hazÄ±rlanmÄ±ÅŸtÄ±r.

**ğŸ·ï¸ Etiketler**: #MachineLearning #KMeans #Clustering #OptimalK #ElbowMethod #SilhouetteAnalysis #DataScience #Python

**â­ Zorluk Seviyesi**: Orta-Ä°leri | **â±ï¸ Tahmini SÃ¼re**: 30-45 dakika | **ğŸ‘¥ Hedef Kitle**: ML Ã¶ÄŸrencileri, veri bilimciler