# 4_lojistikReg_diyabet.py - Lojistik Regresyon (Diyabet Tahmini)

## ğŸ“– Kod AÃ§Ä±klamasÄ±

Bu kod, **lojistik regresyon** (logistic regression) kullanarak diyabet riskini sÄ±nÄ±flandÄ±rÄ±r. DoÄŸrusal regresyondan farklÄ± olarak, **kategorik Ã§Ä±ktÄ±** (0/1, evet/hayÄ±r) tahmin eder.

---

## ğŸ¯ AmaÃ§

HastanÄ±n saÄŸlÄ±k verilerine bakarak **diyabet riskini** (dÃ¼ÅŸÃ¼k/yÃ¼ksek) tahmin etmek.

**Problem Tipi:** Ä°kili SÄ±nÄ±flandÄ±rma (Binary Classification)
- **SÄ±nÄ±f 0:** DÃ¼ÅŸÃ¼k risk / Negatif
- **SÄ±nÄ±f 1:** YÃ¼ksek risk / Pozitif

---

## ğŸ”„ DoÄŸrusal vs Lojistik Regresyon

| Ã–zellik | DoÄŸrusal Regresyon | Lojistik Regresyon |
|---------|--------------------|--------------------|
| **Ã‡Ä±ktÄ± tipi** | SÃ¼rekli sayÄ± | Kategorik (0/1) |
| **Ã–rnek** | Ev fiyatÄ± tahmini | HastalÄ±k var/yok |
| **Fonksiyon** | y = wx + b | y = Ïƒ(wx + b) |
| **AmaÃ§** | DeÄŸer tahmini | SÄ±nÄ±flandÄ±rma |
| **Metrik** | MSE, RÂ² | Accuracy, Precision |

**Sigmoid Fonksiyonu:**
```
Ïƒ(z) = 1 / (1 + e^(-z))
```
Ã‡Ä±ktÄ±yÄ± 0-1 arasÄ±na sÄ±kÄ±ÅŸtÄ±rÄ±r (olasÄ±lÄ±k)

---

## ğŸ“Š Kod Ä°Ã§eriÄŸi ve AdÄ±mlar

### 1. **Veri Seti HazÄ±rlama**
```python
diabetes = load_diabetes()
X = diabetes.data[:, :10]  # 10 Ã¶zellik
y = (diabetes.target > diabetes.target.median()).astype(int)
```

**10 Ã–zellik:**
- age (yaÅŸ)
- sex (cinsiyet)
- bmi (vÃ¼cut kitle indeksi)
- bp (kan basÄ±ncÄ±)
- s1, s2, s3, s4, s5, s6 (Ã§eÅŸitli kan testi sonuÃ§larÄ±)

**Hedef DeÄŸiÅŸken:**
- Orijinal veri sÃ¼rekli â†’ Ä°kili sÄ±nÄ±fa dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼
- Medyan deÄŸerin Ã¼stÃ¼: **1** (YÃ¼ksek risk)
- Medyan deÄŸerin altÄ±: **0** (DÃ¼ÅŸÃ¼k risk)

### 2. **SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±**
```python
print("SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±:", np.bincount(y))
```

**Ã‡Ä±ktÄ±:**
```
SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±: [242 200]
0 (Negatif/DÃ¼ÅŸÃ¼k Risk): 242
1 (Pozitif/YÃ¼ksek Risk): 200
```

Dengeli bir veri seti (iyi durum!)

### 3. **Veri BÃ¶lme**
```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)
```

**stratify=y:** Her sette sÄ±nÄ±f oranlarÄ±nÄ± korur

### 4. **Model EÄŸitimi**
```python
model = LogisticRegression(max_iter=1000, random_state=42)
model.fit(X_train, y_train)
```

**Lojistik Regresyon Denklemi:**
```
P(y=1|X) = Ïƒ(wâ‚xâ‚ + wâ‚‚xâ‚‚ + ... + wâ‚â‚€xâ‚â‚€ + b)
```

- Model, 0.5'ten bÃ¼yÃ¼k olasÄ±lÄ±klarÄ± **1**, kÃ¼Ã§Ã¼kleri **0** olarak sÄ±nÄ±flandÄ±rÄ±r

### 5. **Tahmin ve OlasÄ±lÄ±klar**
```python
y_pred = model.predict(X_test)               # SÄ±nÄ±f (0 veya 1)
y_pred_proba = model.predict_proba(X_test)  # OlasÄ±lÄ±k [P(0), P(1)]
```

**Ã–rnek:**
```
Tahmin: 1 (YÃ¼ksek risk)
OlasÄ±lÄ±klar: [0.38, 0.62]
  â†’ %38 dÃ¼ÅŸÃ¼k risk, %62 yÃ¼ksek risk
```

### 6. **Model PerformansÄ±**
```python
accuracy = accuracy_score(y_test, y_pred)
print(f"Test DoÄŸruluÄŸu: {accuracy:.3f}")
```

**Ã‡Ä±ktÄ±:**
```
Test DoÄŸruluÄŸu: 0.775 (%77.5)
```

### 7. **KarmaÅŸÄ±klÄ±k Matrisi (Confusion Matrix)**
```python
confusion = confusion_matrix(y_test, y_pred)
```

**Ã‡Ä±ktÄ±:**
```
[[44  5]    True Negative: 44  | False Positive: 5
 [15 25]]   False Negative: 15 | True Positive: 25
```

**Yorumlama:**
- **True Negative (44):** DÃ¼ÅŸÃ¼k risk dediÄŸimiz 44 kiÅŸi gerÃ§ekten dÃ¼ÅŸÃ¼k riskli âœ“
- **False Positive (5):** 5 kiÅŸiye yanlÄ±ÅŸ yÃ¼ksek risk dedik âœ—
- **False Negative (15):** 15 yÃ¼ksek riskli hastayÄ± kaÃ§Ä±rdÄ±k âœ— (TEHLÄ°KELÄ°!)
- **True Positive (25):** 25 yÃ¼ksek riskli hastayÄ± doÄŸru bulduk âœ“

### 8. **SÄ±nÄ±flandÄ±rma Raporu**
```python
print(classification_report(y_test, y_pred))
```

**Ã‡Ä±ktÄ±:**
```
              precision    recall  f1-score   support

           0       0.75      0.90      0.81        49
           1       0.83      0.62      0.71        40

    accuracy                           0.78        89
```

**Metrik AÃ§Ä±klamalarÄ±:**

**Precision (Kesinlik):**
```
Precision = TP / (TP + FP)
```
- SÄ±nÄ±f 1 iÃ§in: 25 / (25 + 5) = 0.83
- "Pozitif dediÄŸimizin %83'Ã¼ gerÃ§ekten pozitif"

**Recall (DuyarlÄ±lÄ±k):**
```
Recall = TP / (TP + FN)
```
- SÄ±nÄ±f 1 iÃ§in: 25 / (25 + 15) = 0.62
- "GerÃ§ek pozitiflerin %62'sini bulduk"

**F1-Score (Harmonik Ortalama):**
```
F1 = 2 * (Precision * Recall) / (Precision + Recall)
```

### 9. **Ã–zellik Ã–nemi**
```python
feature_importance = pd.DataFrame({
    'Ã–zellik': feature_names,
    'KatsayÄ±': model.coef_[0]
}).sort_values('KatsayÄ±', key=abs, ascending=False)
```

**Ã‡Ä±ktÄ±:**
```
  Ã–zellik   KatsayÄ±
      s5  2.616106   # EN Ã–NEMLÄ°
     bmi  2.461243
      bp  2.215508
      s3 -1.562480   # Negatif etki
```

**Yorumlama:**
- **s5 (+2.62):** En gÃ¼Ã§lÃ¼ pozitif etki (arttÄ±kÃ§a risk artar)
- **bmi (+2.46):** YÃ¼ksek BMI â†’ YÃ¼ksek risk
- **s3 (-1.56):** Negatif katsayÄ± (arttÄ±kÃ§a risk azalÄ±r)

### 10. **Yeni Hasta Tahmini**
```python
yeni_hasta = [[0.02, -0.04, 0.05, 0.01, -0.03, 0.02, 0.01, 0.00, 0.03, -0.01]]
tahmin = model.predict(yeni_hasta)
olasilik = model.predict_proba(yeni_hasta)
```

**Ã‡Ä±ktÄ±:**
```
Tahmin Edilen SÄ±nÄ±f: 0
OlasÄ±lÄ±k DaÄŸÄ±lÄ±mÄ±: [0.509, 0.491]
Pozitif SÄ±nÄ±f OlasÄ±lÄ±ÄŸÄ±: 0.491
SONUÃ‡: Diyabet riski DÃœÅÃœK
```

---

## ğŸ”‘ Ã–nemli Kavramlar

### **Sigmoid Fonksiyonu**
```python
def sigmoid(z):
    return 1 / (1 + np.exp(-z))
```

- Herhangi bir sayÄ±yÄ± 0-1 arasÄ±na Ã§evirir
- 0.5 eÅŸik deÄŸeri: >0.5 â†’ SÄ±nÄ±f 1, <0.5 â†’ SÄ±nÄ±f 0

### **Karar EÅŸiÄŸi (Decision Threshold)**
```python
# VarsayÄ±lan: 0.5
# Ã–zelleÅŸtirilmiÅŸ:
threshold = 0.7  # Daha muhafazakar
y_pred_custom = (y_pred_proba[:, 1] >= threshold).astype(int)
```

Medikal uygulamalarda False Negative azaltmak iÃ§in eÅŸik dÃ¼ÅŸÃ¼rÃ¼lÃ¼r.

### **Precision vs Recall Trade-off**
- **YÃ¼ksek Precision ister misiniz?** â†’ EÅŸiÄŸi artÄ±rÄ±n (0.7, 0.8)
- **YÃ¼ksek Recall ister misiniz?** â†’ EÅŸiÄŸi azaltÄ±n (0.3, 0.4)
- **Diyabet vakasÄ±nda:** Recall Ã¶nemli (hasta kaÃ§Ä±rmak tehlikeli!)

---

## ğŸ“ˆ Performans Analizi

```
Test DoÄŸruluÄŸu: 77.5%
```

**Ä°yi mi KÃ¶tÃ¼ mÃ¼?**
- Medikal uygulamalarda %77.5 kabul edilebilir ama ideal deÄŸil
- False Negative oranÄ± yÃ¼ksek (15/40 = %37.5)
- GerÃ§ek hastalarda yanlÄ±ÅŸ negatif tehlikelidir!

**Ä°yileÅŸtirme Ã–nerileri:**
1. Daha fazla veri topla
2. Ã–zellik mÃ¼hendisliÄŸi yap
3. EÅŸik deÄŸerini optimize et
4. Ensemble metodlarÄ± dene (Random Forest, XGBoost)

---

## ğŸ“ Ã–ÄŸrenme Hedefleri

âœ… Lojistik regresyon nasÄ±l Ã§alÄ±ÅŸÄ±r
âœ… SÄ±nÄ±flandÄ±rma problemleri nasÄ±l Ã§Ã¶zÃ¼lÃ¼r
âœ… Confusion matrix nasÄ±l yorumlanÄ±r
âœ… Precision, Recall, F1-Score ne demek
âœ… OlasÄ±lÄ±k tahmini nasÄ±l yapÄ±lÄ±r
âœ… Ã–zellik Ã¶nem analizi nasÄ±l yapÄ±lÄ±r
âœ… Medikal veri analizi temelleri

---

## ğŸš€ NasÄ±l Ã‡alÄ±ÅŸtÄ±rÄ±lÄ±r?

```bash
python 4_lojistikReg_diyabet.py
```

---

## ğŸ“¦ Gerekli KÃ¼tÃ¼phaneler

```python
numpy
pandas
scikit-learn
```

---

## ğŸ” Ä°leri Seviye Ä°Ã§in

### **1. ROC EÄŸrisi ve AUC Skoru**
```python
from sklearn.metrics import roc_curve, auc
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba[:, 1])
roc_auc = auc(fpr, tpr)
print(f"AUC: {roc_auc:.3f}")
```

### **2. Hiperparametre Optimizasyonu**
```python
from sklearn.model_selection import GridSearchCV
param_grid = {'C': [0.01, 0.1, 1, 10, 100]}
grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)
grid_search.fit(X_train, y_train)
```

### **3. Class Weight (Dengesiz Veri iÃ§in)**
```python
model = LogisticRegression(class_weight='balanced')
```

---

## ğŸ†š Regresyon KarÅŸÄ±laÅŸtÄ±rmasÄ±

| Model | Problem | Ã‡Ä±ktÄ± | Ã–rnek |
|-------|---------|-------|-------|
| **DoÄŸrusal** | Regresyon | SÃ¼rekli sayÄ± | Fiyat: 250,000 TL |
| **Lojistik** | SÄ±nÄ±flandÄ±rma | Kategori (0/1) | Risk: YÃ¼ksek |

---

## ğŸ“Œ Notlar

- **False Negative** medikal uygulamalarda Ã§ok kritik!
- Recall'u artÄ±rmak iÃ§in eÅŸik deÄŸeri dÃ¼ÅŸÃ¼rÃ¼lebilir
- Model basit ama etkili (yorumlanabilir)
- Daha karmaÅŸÄ±k modellerle (SVM, Neural Nets) performans artÄ±rÄ±labilir

---

**HazÄ±rlayan:** BTK AtÃ¶lye - Multimedya GÃ¼venliÄŸi
**Tarih:** 2025
**Seviye:** Orta-Ä°leri
